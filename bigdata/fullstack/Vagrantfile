# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. The "2" in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don't change it unless you know what
# you're doing.
Vagrant.configure("2") do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://vagrantcloud.com/search.
  config.vm.box = "ubuntu/bionic64"
  # config.vm.box = "centos/7"

  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`. This is not recommended.
  # config.vm.box_check_update = false

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing "localhost:8080" will access port 80 on the guest machine.
  # NOTE: This will enable public access to the opened port
  # config.vm.network "forwarded_port", guest: 80, host: 8080

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine and only allow access
  # via 127.0.0.1 to disable public access
  # config.vm.network "forwarded_port", guest: 80, host: 8080, host_ip: "127.0.0.1"

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.
  # config.vm.network "private_network", ip: "192.168.33.10"

  # Create a public network, which generally matched to bridged network.
  # Bridged networks make the machine appear as another physical device on
  # your network.
  # config.vm.network "public_network"

  # Share an additional folder to the guest VM. The first argument is
  # the path on the host to the actual folder. The second argument is
  # the path on the guest to mount the folder. And the optional third
  # argument is a set of non-required options.
  # config.vm.synced_folder "../data", "/vagrant_data"

  # Provider-specific configuration so you can fine-tune various
  # backing providers for Vagrant. These expose provider-specific options.
  # Example for VirtualBox:
  #
  # config.vm.provider "virtualbox" do |vb|
  #   # Display the VirtualBox GUI when booting the machine
  #   vb.gui = true
  #
  #   # Customize the amount of memory on the VM:
  #   vb.memory = "1024"
  # end
  #
  # View the documentation for the provider you are using for more
  # information on available options.

  # Enable provisioning with a shell script. Additional provisioners such as
  # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the
  # documentation for more information about their specific syntax and use.
  config.vm.provision "shell", inline: <<-SHELL
    APACHE_DIST=https://apache.org/dist
    APACHE_MIRROR=http://mirrors.viethosting.com/apache

    apt update
    apt install -y openjdk-8-jdk
    # yum install -y java-1.8.0-openjdk-devel
    export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:/bin/java::")

    cd /opt
    export HIVE_VERSION=3.1.1
    export HIVE_HOME=/opt/hive
    export SPARK_VERSION=2.4.0
    export SPARK_HOME=/opt/spark
    export HADOOP_VERSION=3.1.2
    export HADOOP_HOME=/opt/hadoop
    export PYTHONPATH="${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.7-src.zip"

    if [ ! -d "${HADOOP_HOME}" ]; then
      curl -LO "${APACHE_MIRROR}/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz";
      tar -xzf "hadoop-${HADOOP_VERSION}.tar.gz" --owner root --group root --no-same-owner;
      rm  -rf  "hadoop-${HADOOP_VERSION}.tar.gz";
      mv       "hadoop-${HADOOP_VERSION}" hadoop;
    fi

    if [ ! -d "${SPARK_HOME}" ]; then
      curl -LO "${APACHE_MIRROR}/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-without-hadoop.tgz";
      tar -xzf "spark-${SPARK_VERSION}-bin-without-hadoop.tgz" --owner root --group root --no-same-owner;
      rm  -rf  "spark-${SPARK_VERSION}-bin-without-hadoop.tgz"
      mv       "spark-${SPARK_VERSION}-bin-without-hadoop" spark;
    fi

    if [ ! -d "${HIVE_HOME}" ]; then
      curl -LO "${APACHE_MIRROR}/hive/hive-${HIVE_VERSION}/apache-hive-${HIVE_VERSION}-bin.tar.gz";
      tar -xzf "apache-hive-${HIVE_VERSION}-bin.tar.gz" --owner root --group root --no-same-owner;
      rm  -rf  "apache-hive-${HIVE_VERSION}-bin.tar.gz";
      mv       "apache-hive-${HIVE_VERSION}-bin" hive;
    fi

    if [ ! -f ~/.ssh/id_rsa ]; then
      ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa -C "bigdata@teko.vn"
      cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    fi

    ln -s /usr/bin/python3    /usr/bin/python
    cp /vagrant/spark-conf/*  /opt/spark/conf/
    cp /vagrant/hadoop-conf/* /opt/hadoop/etc/hadoop/
  SHELL

  # config.vm.provision "file", source: "spark-conf/*", destination: "/opt/spark/conf/"
  # config.vm.provision "file", source: "hadoop-conf/*", destination: "/opt/hadoop/etc/hadoop/"
  # export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")
  # ./bin/hdfs namenode -format
  # ./sbin/start-dfs.sh
end
